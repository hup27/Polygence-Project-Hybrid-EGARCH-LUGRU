{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eaf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GARCH'''\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "\n",
    "def b1_square(x_view: np.ndarray) -> np.ndarray:\n",
    "    return np.square(x_view[-1, :])\n",
    "\n",
    "\n",
    "def b1(sigma_view: np.ndarray) -> np.ndarray:\n",
    "    return sigma_view[-1, :]\n",
    "\n",
    "\n",
    "def loglik(ret: np.ndarray, params: Sequence, vola_ret_features=b1_square, vola_sigma_features=b1):\n",
    "    \"\"\"Calculate the likelihood of a process path\"\"\"\n",
    "    ret = ret.reshape((-1, 1))\n",
    "    gamma_0, gamma_1, lambda_1 = params\n",
    "    sigma_squared = np.repeat(gamma_0, len(ret)).reshape(ret.shape)\n",
    "    sigma_squared[0, 0] = gamma_0\n",
    "\n",
    "    for s in range(1, len(ret)):\n",
    "        sigma_squared[s, :] = (\n",
    "            gamma_0\n",
    "            + np.dot(gamma_1, vola_ret_features(ret[0:s, :]))\n",
    "            + np.dot(lambda_1, vola_sigma_features(sigma_squared[0:s, :]))\n",
    "        )\n",
    "\n",
    "    return np.sum(scipy.stats.norm.logpdf(ret[1:, 0], loc=0.0, scale=np.sqrt(sigma_squared[1:, 0])))\n",
    "\n",
    "\n",
    "def mle(ret: np.ndarray, start_params: Sequence):\n",
    "    \"\"\"Maximum-likelihood estimator\"\"\"\n",
    "\n",
    "    def error_fuc(theta):\n",
    "        return -loglik(ret, theta)\n",
    "\n",
    "    start_params = np.array(start_params)\n",
    "    result = scipy.optimize.minimize(\n",
    "        error_fuc,\n",
    "        start_params,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=[(1e-8, 1.0), (1e-8, 1.0), (1e-8, 1.0)],\n",
    "        options={'maxiter': 250, 'disp': False},\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def path(\n",
    "    no_paths: int, t: int, params: Sequence, vola_ret_features=b1_square, vola_sigma_features=b1\n",
    "):\n",
    "    \"\"\"Simulate process paths\"\"\"\n",
    "    assert no_paths > 0 and t > 0\n",
    "    assert len(params) == 3\n",
    "\n",
    "    ret = np.random.randn(t, no_paths)\n",
    "    gamma_0, gamma_1, lambda_1 = params\n",
    "    gamma_0 = np.repeat(gamma_0, no_paths).reshape((1, no_paths))\n",
    "    sigma_squared = np.zeros((t, no_paths))\n",
    "    sigma_squared[0, :] = gamma_0\n",
    "    ret[0, :] = 0.0\n",
    "\n",
    "    for s in range(1, t):\n",
    "        sigma_squared[s, :] = (\n",
    "            gamma_0\n",
    "            + np.dot(gamma_1, vola_ret_features(ret[0:s, :]))\n",
    "            + np.dot(lambda_1, vola_sigma_features(sigma_squared[0:s, :]))\n",
    "        )\n",
    "        ret[s, :] = ret[s, :] * np.sqrt(sigma_squared[s, :])\n",
    "\n",
    "    return ret, np.sqrt(sigma_squared)\n",
    "\n",
    "\n",
    "def noise_from_path(\n",
    "    ret: np.ndarray, params: Sequence, vola_ret_features=b1_square, vola_sigma_features=b1\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Extract the noise process path from a GARCH path given a parameter set\"\"\"\n",
    "    ret = ret.reshape((-1, 1))\n",
    "    gamma_0, gamma_1, lambda_1 = params\n",
    "    sigma_squared = np.repeat(gamma_0, len(ret)).reshape(ret.shape)\n",
    "    sigma_squared[0, 0] = gamma_0\n",
    "    noise = np.zeros(ret.shape)\n",
    "\n",
    "    noise[0, :] = ret[0, :] / np.sqrt(sigma_squared[0, :])\n",
    "    for s in range(1, len(ret)):\n",
    "        sigma_squared[s, :] = (\n",
    "            gamma_0\n",
    "            + np.dot(gamma_1, vola_ret_features(ret[0:s, :]))\n",
    "            + np.dot(lambda_1, vola_sigma_features(sigma_squared[0:s, :]))\n",
    "        )\n",
    "        noise[s, :] = ret[s, :] / np.sqrt(sigma_squared[s, :])\n",
    "    return noise\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plt.style.use('ggplot')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32eb2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EGARCH'''\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "\n",
    "def b1_square(x_view: np.ndarray) -> np.ndarray:\n",
    "    return np.square(x_view[-1, :])\n",
    "\n",
    "\n",
    "def b1(sigma_view: np.ndarray) -> np.ndarray:\n",
    "    return sigma_view[-1, :]\n",
    "\n",
    "E_ABS_Z = np.sqrt(2 / np.pi)\n",
    "\n",
    "def loglik(ret: np.ndarray, params: Sequence, vola_ret_features=b1_square, vola_sigma_features=b1):\n",
    "    \"\"\"Calculate the likelihood of a process path\"\"\"\n",
    "    ret = ret.reshape((-1, 1))\n",
    "    omega, alpha, gamma, beta = params\n",
    "    log_sigma_squared = np.zeros_like(ret)\n",
    "    log_sigma_squared[0, 0] = omega\n",
    "\n",
    "    for s in range(1, len(ret)):\n",
    "        sigma_prev = np.sqrt(np.exp(log_sigma_squared[s - 1, 0]))\n",
    "        z_prev = ret[s - 1, 0] / sigma_prev\n",
    "        log_sigma_squared[s, :] = (\n",
    "            omega\n",
    "            + beta * np.log(sigma_prev**2)\n",
    "            + alpha * (np.abs(z_prev) - E_ABS_Z)\n",
    "            + gamma * z_prev\n",
    "        )\n",
    "\n",
    "    sigma_squared = np.exp(log_sigma_squared)\n",
    "\n",
    "    return np.sum(scipy.stats.norm.logpdf(ret[1:, 0], loc=0.0, scale=np.sqrt(sigma_squared[1:, 0])))\n",
    "\n",
    "\n",
    "def mle(ret: np.ndarray, start_params: Sequence):\n",
    "    \"\"\"Maximum-likelihood estimator\"\"\"\n",
    "\n",
    "    def error_fuc(theta):\n",
    "        return -loglik(ret, theta)\n",
    "\n",
    "    start_params = np.array(start_params)\n",
    "    result = scipy.optimize.minimize(\n",
    "        error_fuc,\n",
    "        start_params,\n",
    "        method='L-BFGS-B',\n",
    "        bounds = [\n",
    "        (None, None),   # omega\n",
    "        (0.0, 1.0),     # alpha\n",
    "        (None, None),   # gamma\n",
    "        (0.0, 1.0)],    # beta]\n",
    "        options={'maxiter': 250, 'disp': False},\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def path(\n",
    "    no_paths: int, t: int, params: Sequence, vola_ret_features=b1_square, vola_sigma_features=b1\n",
    "):\n",
    "    \"\"\"Simulate process paths\"\"\"\n",
    "    assert no_paths > 0 and t > 0\n",
    "    assert len(params) == 3\n",
    "\n",
    "    ret = np.random.randn(t, no_paths)\n",
    "    omega, alpha, gamma, beta = params\n",
    "    log_sigma_squared = np.zeros((t, no_paths))\n",
    "    log_sigma_squared[0, :] = omega\n",
    "    z = np.random.randn(t, no_paths)\n",
    "    ret[0, :] = 0.0\n",
    "\n",
    "    for s in range(1, t):\n",
    "        sigma_prev = np.sqrt(np.exp(log_sigma_squared[s - 1, :]))\n",
    "        z_prev = ret[s - 1, :] / sigma_prev\n",
    "        log_sigma_squared[s, :] = (\n",
    "            omega\n",
    "            + beta * np.log(sigma_prev**2)\n",
    "            + alpha * (np.abs(z_prev) - E_ABS_Z)\n",
    "            + gamma * z_prev\n",
    "        )\n",
    "        ret[s, :] = z[s, :] * np.sqrt(log_sigma_squared[s, :])\n",
    "\n",
    "    return ret, np.sqrt(log_sigma_squared)\n",
    "\n",
    "\n",
    "def noise_from_path(ret: np.ndarray, params: Sequence):\n",
    "    \"\"\"\n",
    "    Extract standardized residuals z_t from EGARCH path\n",
    "    \"\"\"\n",
    "\n",
    "    ret = ret.reshape((-1, 1))\n",
    "    omega, alpha, gamma, beta = params\n",
    "\n",
    "    log_sigma_sq = np.zeros_like(ret)\n",
    "    log_sigma_sq[0, 0] = omega\n",
    "    z = np.zeros_like(ret)\n",
    "\n",
    "    for t in range(1, len(ret)):\n",
    "        sigma_prev = np.sqrt(np.exp(log_sigma_sq[t - 1, 0]))\n",
    "        z_prev = ret[t - 1, 0] / sigma_prev\n",
    "\n",
    "        log_sigma_sq[t, 0] = (\n",
    "            omega\n",
    "            + beta * log_sigma_sq[t - 1, 0]\n",
    "            + alpha * (np.abs(z_prev) - E_ABS_Z)\n",
    "            + gamma * z_prev\n",
    "        )\n",
    "\n",
    "        z[t, 0] = ret[t, 0] / np.sqrt(np.exp(log_sigma_sq[t, 0]))\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plt.style.use('ggplot')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b93655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GRU\"\"\"\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim) -> None:\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_dim, self.hidden_dim = input_dim, hidden_dim\n",
    "        self.relevance_whh, self.relevance_wxh, self.relevance_b = self.create_gate_parameters()\n",
    "        self.update_whh, self.update_wxh, self.update_b = self.create_gate_parameters()\n",
    "        self.candidate_whh, self.candidate_wxh, self.candidate_b = self.create_gate_parameters()\n",
    "\n",
    "    def create_gate_parameters(self):\n",
    "        input_weights = nn.Parameter(torch.zeros(self.input_dim, self.hidden_dim))\n",
    "        hidden_weights = nn.Parameter(torch.zeros(self.hidden_dim, self.hidden_dim))\n",
    "        nn.init.xavier_uniform_(input_weights)\n",
    "        nn.init.xavier_uniform_(hidden_weights)\n",
    "        bias = nn.Parameter(torch.zeros(self.hidden_dim))\n",
    "        return hidden_weights, input_weights, bias\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        output_hiddens = []\n",
    "        for i in range(x.shape[1]):\n",
    "            relevance_gate = F.sigmoid((h @ self.relevance_whh) + (x[:, i] @ self.relevance_wxh) + self.relevance_b)\n",
    "            update_gate = F.sigmoid((h @ self.update_whh) + (x[:, i] @ self.update_wxh) + self.update_b)\n",
    "            candidate_hidden = F.tanh(((relevance_gate * h) @ self.candidate_whh) + (x[:, i] @ self.candidate_wxh) + self.candidate_b)\n",
    "            h = (update_gate * candidate_hidden) + ((1 - update_gate) * h)\n",
    "            output_hiddens.append(h.unsqueeze(1))\n",
    "        return torch.concat(output_hiddens, dim=1)\n",
    "\n",
    "\n",
    "class MultiLayerGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(MultiLayerGRU, self).__init__()\n",
    "        self.input_dim, self.hidden_dim, self.num_layers = input_dim, hidden_dim, num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(GRUCell(input_dim, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(GRUCell(hidden_dim, hidden_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(hidden_dim, input_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight.data)\n",
    "        self.linear.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        output_hidden = self.layers[0](x, h[0])\n",
    "        new_hidden = [output_hidden[:, -1].unsqueeze(0)]\n",
    "        for i in range(1, self.num_layers):\n",
    "            output_hidden = self.layers[i](self.dropout(output_hidden), h[i])\n",
    "            new_hidden.append(output_hidden[:, -1].unsqueeze(0))\n",
    "        return self.linear(self.dropout(output_hidden)), torch.concat(new_hidden, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6082f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"LIGRU\"\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim) -> None:\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_dim, self.hidden_dim = input_dim, hidden_dim\n",
    "        self.update_whh, self.update_wxh, self.update_b = self.create_gate_parameters()\n",
    "        self.candidate_whh, self.candidate_wxh, self.candidate_b = self.create_gate_parameters()\n",
    "\n",
    "    def create_gate_parameters(self):\n",
    "        input_weights = nn.Parameter(torch.zeros(self.input_dim, self.hidden_dim))\n",
    "        hidden_weights = nn.Parameter(torch.zeros(self.hidden_dim, self.hidden_dim))\n",
    "        nn.init.xavier_uniform_(input_weights)\n",
    "        nn.init.xavier_uniform_(hidden_weights)\n",
    "        bias = nn.Parameter(torch.zeros(self.hidden_dim))\n",
    "        return hidden_weights, input_weights, bias\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        output_hiddens = []\n",
    "        for i in range(x.shape[1]):\n",
    "            update_gate = F.sigmoid((h @ self.update_whh) + (x[:, i] @ self.update_wxh) + self.update_b)\n",
    "            candidate_hidden = F.relu((h @ self.candidate_whh) + ((x[:, i] @ self.candidate_wxh) + self.candidate_b))\n",
    "            h = (update_gate * candidate_hidden) + ((1 - update_gate) * h)\n",
    "            output_hiddens.append(h.unsqueeze(1))\n",
    "        return torch.concat(output_hiddens, dim=1)\n",
    "\n",
    "\n",
    "class MultiLayerGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(MultiLayerGRU, self).__init__()\n",
    "        self.input_dim, self.hidden_dim, self.num_layers = input_dim, hidden_dim, num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(GRUCell(input_dim, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(GRUCell(hidden_dim, hidden_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(hidden_dim, input_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight.data)\n",
    "        self.linear.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        output_hidden = self.layers[0](x, h[0])\n",
    "        new_hidden = [output_hidden[:, -1].unsqueeze(0)]\n",
    "        for i in range(1, self.num_layers):\n",
    "            output_hidden = self.layers[i](self.dropout(output_hidden), h[i])\n",
    "            new_hidden.append(output_hidden[:, -1].unsqueeze(0))\n",
    "        return self.linear(self.dropout(output_hidden)), torch.concat(new_hidden, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5412467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: [-0.83507327  0.          0.05807386  0.81580395]\n",
      "Log-likelihood: 110.93286401599653\n"
     ]
    }
   ],
   "source": [
    "\"Example Usage\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = pd.read_csv(\"airline-passengers.csv\")\n",
    "\n",
    "# parse time\n",
    "dataset[\"Month\"] = pd.to_datetime(dataset[\"Month\"])\n",
    "dataset = dataset.sort_values(\"Month\")\n",
    "\n",
    "values = dataset[\"Passengers\"].values.astype(\"float32\")\n",
    "log_values = np.log(values)\n",
    "\n",
    "returns = np.diff(log_values)\n",
    "returns = returns - returns.mean()\n",
    "start_params = [-0.1, 0.1, 0.0, 0.9]\n",
    "result = mle(returns, start_params)\n",
    "params_hat = result.x\n",
    "\n",
    "print(\"Estimated parameters:\", params_hat)\n",
    "\n",
    "ll_value = loglik(returns, params_hat)\n",
    "print(\"Log-likelihood:\", ll_value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
